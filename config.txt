do_training: true
max_iterations: int 128
error_cutoff: float 8e-5
learn_rate: float 1.5e-5
batch_size: int 30
dropout: float 0.05
betas: float[0.9, 0.95]
weight_decay: float 0
epsilon: float 1e-5

print_weights: false

# how often to print out training loss (in # of iterations)
printout_period: int 8
checkpoint_period: int 2

network_topology: int[16384,5]

# "sigmoid", "tanh", or "leaky_relu"
activation_function: "tanh"

# "randomize", "from_file"
initialization_mode: "randomize"
rand_lo: float -0.001
rand_hi: float 0.001

# load_file is not used with initialization_mode="randomize"
load_file: "trash.net"
save_file: "trash.net"

# In the future, I will implement loading training data from a binary file or directory.
dataset_mode: "from_file"
dataset_file: "dataset/.secret.data"
case [0,0]: float[0,0,0]
case [0,1]: float[0,1,1]
case [1,0]: float[0,1,1]
case [1,1]: float[1,1,0]


# expected results for configs
# 2-5-3    ~40-60k its
# 2-20-3   ~20k its
# 2-100-3  1,1,1,---   0.75 err
# 2-2-3    0.719
# 2-1-3    0.3,0.8,0.5
# A>2
# 2-10-3   train/save then load weights
