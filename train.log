parsed configuration from file `config.txt`
	activation_function: Text("sigmoid")
	add_noise: Numeric(0.17)
	error_cutoff: Numeric(0.0008)
	gain: Numeric(2.1)
	initialization_mode: Text("smart_random")
	input_dropout: Numeric(0.6)
	learn_rate: Numeric(0.1)
	max_iterations: Integer(1024)
	network_topology: IntList([16384, 24, 24, 5])
Loaded 25 datapoints from dataset/train.data
loss=0.517326	acc=0.00	λ=0.100000	it=0
loss=0.406249	acc=0.00	λ=0.100000	it=8
loss=0.406218	acc=0.00	λ=0.100000	it=16
loss=0.406250	acc=0.00	λ=0.100000	it=24
loss=0.406291	acc=0.00	λ=0.100000	it=32
loss=0.406312	acc=0.00	λ=0.100000	it=40
loss=0.406351	acc=0.00	λ=0.100000	it=48
loss=0.406367	acc=0.00	λ=0.100000	it=56
loss=0.406378	acc=0.00	λ=0.100000	it=64
loss=0.406371	acc=0.00	λ=0.100000	it=72
loss=0.406324	acc=0.00	λ=0.100000	it=80
loss=0.406320	acc=0.00	λ=0.100000	it=88
loss=0.406210	acc=0.00	λ=0.100000	it=96
loss=0.406024	acc=0.00	λ=0.100000	it=104
loss=0.405719	acc=0.00	λ=0.100000	it=112
loss=0.405498	acc=0.00	λ=0.100000	it=120
loss=0.404831	acc=0.00	λ=0.100000	it=128
loss=0.404055	acc=0.00	λ=0.100000	it=136
loss=0.402997	acc=12.00	λ=0.100000	it=144
loss=0.400644	acc=20.00	λ=0.100000	it=152
loss=0.397593	acc=20.00	λ=0.100000	it=160
loss=0.391948	acc=20.00	λ=0.100000	it=168
loss=0.383596	acc=20.00	λ=0.100000	it=176
loss=0.369058	acc=20.00	λ=0.100000	it=184
loss=0.351670	acc=20.00	λ=0.100000	it=192
loss=0.337874	acc=20.00	λ=0.100000	it=200
loss=0.329597	acc=24.00	λ=0.100000	it=208
loss=0.321891	acc=24.00	λ=0.100000	it=216
loss=0.316533	acc=24.00	λ=0.100000	it=224
loss=0.316583	acc=28.00	λ=0.100000	it=232
loss=0.313674	acc=24.00	λ=0.100000	it=240
loss=0.311009	acc=32.00	λ=0.100000	it=248
loss=0.313157	acc=28.00	λ=0.100000	it=256
loss=0.310195	acc=28.00	λ=0.100000	it=264
loss=0.305031	acc=28.00	λ=0.100000	it=272
loss=0.299895	acc=36.00	λ=0.100000	it=280
loss=0.301131	acc=36.00	λ=0.100000	it=288
loss=0.300938	acc=36.00	λ=0.100000	it=296
loss=0.297514	acc=36.00	λ=0.100000	it=304
loss=0.297727	acc=40.00	λ=0.100000	it=312
loss=0.290360	acc=48.00	λ=0.100000	it=320
loss=0.285956	acc=48.00	λ=0.100000	it=328
loss=0.282625	acc=56.00	λ=0.100000	it=336
loss=0.278712	acc=60.00	λ=0.100000	it=344
loss=0.271129	acc=64.00	λ=0.100000	it=352
loss=0.261679	acc=68.00	λ=0.100000	it=360
loss=0.251841	acc=72.00	λ=0.100000	it=368
loss=0.242567	acc=80.00	λ=0.100000	it=376
loss=0.229849	acc=72.00	λ=0.100000	it=384
loss=0.216031	acc=84.00	λ=0.100000	it=392
loss=0.202029	acc=92.00	λ=0.100000	it=400
loss=0.178108	acc=96.00	λ=0.100000	it=408
loss=0.158269	acc=96.00	λ=0.100000	it=416
loss=0.140598	acc=100.00	λ=0.100000	it=424
loss=0.116180	acc=100.00	λ=0.100000	it=432
loss=0.100340	acc=100.00	λ=0.100000	it=440
loss=0.088976	acc=100.00	λ=0.100000	it=448
loss=0.070778	acc=100.00	λ=0.100000	it=456
loss=0.057696	acc=100.00	λ=0.100000	it=464
loss=0.051105	acc=100.00	λ=0.100000	it=472
loss=0.050225	acc=100.00	λ=0.100000	it=480
loss=0.034845	acc=100.00	λ=0.100000	it=488
loss=0.029272	acc=100.00	λ=0.100000	it=496
loss=0.028327	acc=100.00	λ=0.100000	it=504
loss=0.025893	acc=100.00	λ=0.100000	it=512
loss=0.019717	acc=100.00	λ=0.100000	it=520
loss=0.019943	acc=100.00	λ=0.100000	it=528
loss=0.018428	acc=100.00	λ=0.100000	it=536
loss=0.015615	acc=100.00	λ=0.100000	it=544
loss=0.022309	acc=100.00	λ=0.100000	it=552
loss=0.016777	acc=100.00	λ=0.100000	it=560
loss=0.011279	acc=100.00	λ=0.100000	it=568
loss=0.012179	acc=100.00	λ=0.100000	it=576
loss=0.011704	acc=100.00	λ=0.100000	it=584
loss=0.010729	acc=100.00	λ=0.100000	it=592
loss=0.010031	acc=100.00	λ=0.100000	it=600
loss=0.008241	acc=100.00	λ=0.100000	it=608
loss=0.007663	acc=100.00	λ=0.100000	it=616
loss=0.009287	acc=100.00	λ=0.100000	it=624
loss=0.006018	acc=100.00	λ=0.100000	it=632
loss=0.008767	acc=100.00	λ=0.100000	it=640
loss=0.009635	acc=100.00	λ=0.100000	it=648
loss=0.005616	acc=100.00	λ=0.100000	it=656
loss=0.006828	acc=100.00	λ=0.100000	it=664
loss=0.006230	acc=100.00	λ=0.100000	it=672
loss=0.004924	acc=100.00	λ=0.100000	it=680
loss=0.008153	acc=100.00	λ=0.100000	it=688
loss=0.007294	acc=100.00	λ=0.100000	it=696
loss=0.005409	acc=100.00	λ=0.100000	it=704
loss=0.004500	acc=100.00	λ=0.100000	it=712
loss=0.004313	acc=100.00	λ=0.100000	it=720
loss=0.005082	acc=100.00	λ=0.100000	it=728
loss=0.004956	acc=100.00	λ=0.100000	it=736
loss=0.004048	acc=100.00	λ=0.100000	it=744
loss=0.004515	acc=100.00	λ=0.100000	it=752
loss=0.005138	acc=100.00	λ=0.100000	it=760
loss=0.003935	acc=100.00	λ=0.100000	it=768
loss=0.003488	acc=100.00	λ=0.100000	it=776
loss=0.003340	acc=100.00	λ=0.100000	it=784
loss=0.003540	acc=100.00	λ=0.100000	it=792
loss=0.004851	acc=100.00	λ=0.100000	it=800
loss=0.003863	acc=100.00	λ=0.100000	it=808
loss=0.003013	acc=100.00	λ=0.100000	it=816
loss=0.002613	acc=100.00	λ=0.100000	it=824
loss=0.004334	acc=100.00	λ=0.100000	it=832
loss=0.002762	acc=100.00	λ=0.100000	it=840
loss=0.003118	acc=100.00	λ=0.100000	it=848
loss=0.002197	acc=100.00	λ=0.100000	it=856
loss=0.003166	acc=100.00	λ=0.100000	it=864
loss=0.002621	acc=100.00	λ=0.100000	it=872
loss=0.002273	acc=100.00	λ=0.100000	it=880
loss=0.002863	acc=100.00	λ=0.100000	it=888
loss=0.002460	acc=100.00	λ=0.100000	it=896
loss=0.002147	acc=100.00	λ=0.100000	it=904
loss=0.002542	acc=100.00	λ=0.100000	it=912
loss=0.004327	acc=100.00	λ=0.100000	it=920
loss=0.002034	acc=100.00	λ=0.100000	it=928
loss=0.001826	acc=100.00	λ=0.100000	it=936
loss=0.002093	acc=100.00	λ=0.100000	it=944
loss=0.002340	acc=100.00	λ=0.100000	it=952
loss=0.002463	acc=100.00	λ=0.100000	it=960
loss=0.002166	acc=100.00	λ=0.100000	it=968
loss=0.002245	acc=100.00	λ=0.100000	it=976
loss=0.002781	acc=100.00	λ=0.100000	it=984
loss=0.001930	acc=100.00	λ=0.100000	it=992
loss=0.001543	acc=100.00	λ=0.100000	it=1000
loss=0.001811	acc=100.00	λ=0.100000	it=1008
loss=0.001574	acc=100.00	λ=0.100000	it=1016

Terminated training after 1024/1024 iterations
loss=0.001790, threshold=0.000800
	+ Reached maximum number of iterations

Trained in 103.6141 seconds (101.1857ms per epoch, 4.0474ms per case)

Truth table
network = [0.9897684, 0.03189923, 0.00015271096, 0.034069005, 2.6337717e-5] (expected [1.00, 0.00, 0.00, 0.00, 0.00])
network = [0.030183027, 0.9920333, 0.018079907, 0.00015288287, 9.397414e-6] (expected [0.00, 1.00, 0.00, 0.00, 0.00])
network = [2.5354137e-5, 0.042331465, 0.98730797, 0.0024863228, 0.015683476] (expected [0.00, 0.00, 1.00, 0.00, 0.00])
network = [0.050687257, 9.0874655e-6, 0.0033024019, 0.98040223, 0.01169646] (expected [0.00, 0.00, 0.00, 1.00, 0.00])
network = [6.385111e-5, 1.1615952e-6, 0.018690398, 0.018281741, 0.9830602] (expected [0.00, 0.00, 0.00, 0.00, 1.00])
network = [0.9898151, 0.028461872, 0.00013630993, 0.036555424, 2.7889773e-5] (expected [1.00, 0.00, 0.00, 0.00, 0.00])
network = [0.031627923, 0.99217343, 0.019501721, 0.00015836282, 9.3965e-6] (expected [0.00, 1.00, 0.00, 0.00, 0.00])
network = [3.5826502e-5, 0.0309337, 0.9869647, 0.0034453443, 0.015035828] (expected [0.00, 0.00, 1.00, 0.00, 0.00])
network = [0.056304462, 6.41284e-6, 0.0028625028, 0.9802973, 0.015780887] (expected [0.00, 0.00, 0.00, 1.00, 0.00])
network = [5.8660306e-5, 1.2320538e-6, 0.020073382, 0.01763449, 0.9830771] (expected [0.00, 0.00, 0.00, 0.00, 1.00])
network = [0.9894332, 0.0363474, 0.000179175, 0.031851083, 2.4766516e-5] (expected [1.00, 0.00, 0.00, 0.00, 0.00])
network = [0.028444229, 0.9920942, 0.019427616, 0.0001505888, 9.597183e-6] (expected [0.00, 1.00, 0.00, 0.00, 0.00])
network = [1.944101e-5, 0.05005089, 0.98734635, 0.0011932862, 0.018145492] (expected [0.00, 0.00, 1.00, 0.00, 0.00])
network = [0.052614316, 6.9362113e-6, 0.0030315137, 0.98036367, 0.014635763] (expected [0.00, 0.00, 0.00, 1.00, 0.00])
network = [7.411531e-5, 1.0686371e-6, 0.016969362, 0.01992578, 0.9828714] (expected [0.00, 0.00, 0.00, 0.00, 1.00])
network = [0.989588, 0.031158963, 0.00015561795, 0.035085022, 2.6689879e-5] (expected [1.00, 0.00, 0.00, 0.00, 0.00])
network = [0.033569027, 0.9920101, 0.019839572, 0.00016710436, 9.22544e-6] (expected [0.00, 1.00, 0.00, 0.00, 0.00])
network = [1.9846724e-5, 0.041227523, 0.98717856, 0.0009920459, 0.02204891] (expected [0.00, 0.00, 1.00, 0.00, 0.00])
network = [0.07648057, 7.930079e-6, 0.003196487, 0.98242515, 0.011799741] (expected [0.00, 0.00, 0.00, 1.00, 0.00])
network = [6.704811e-5, 1.2009257e-6, 0.018193478, 0.019536486, 0.98222864] (expected [0.00, 0.00, 0.00, 0.00, 1.00])
network = [0.9896081, 0.036213666, 0.00017642019, 0.03191659, 2.4795796e-5] (expected [1.00, 0.00, 0.00, 0.00, 0.00])
network = [0.04820308, 0.9923219, 0.018509556, 0.00020847043, 8.337758e-6] (expected [0.00, 1.00, 0.00, 0.00, 0.00])
network = [3.0994554e-5, 0.04550185, 0.98668146, 0.002139236, 0.014909465] (expected [0.00, 0.00, 1.00, 0.00, 0.00])
network = [0.05815559, 7.236334e-6, 0.0032173526, 0.9810953, 0.013881502] (expected [0.00, 0.00, 0.00, 1.00, 0.00])
network = [6.786292e-5, 1.1895783e-6, 0.018966667, 0.019985965, 0.9824469] (expected [0.00, 0.00, 0.00, 0.00, 1.00])
Ran epoch in 15.5610ms (0.6224ms per case)
final loss: 0.0011402271	final accuracy: 100

saved neural network to file `network2.net`
